{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4069db79-b941-40f6-b00d-59e3c96dd22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year                  team           Player   salary  playerID Team Pos  \\\n",
      "0  2019  arizona-diamondbacks  Eduardo Escobar  6166666    500871  ARI  3B   \n",
      "\n",
      "   Age    G   AB  ...  CS  BB   SO  SH  SF  HBP    AVG   OBP    SLG    OPS  \n",
      "0   35  158  636  ...   1  50  130   0  10    3  0.269  0.32  0.511  0.831  \n",
      "\n",
      "[1 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "salaries_df = pd.read_csv('/Users/ranch/Desktop/DSCI303/mlbSalaries.csv')\n",
    "batters_df = pd.read_csv('/Users/ranch/Desktop/DSCI303/mlb-player-stats-Batters.csv')\n",
    "\n",
    "# Rename columns so the datasets can be joined\n",
    "salaries_df.rename(columns={'name': 'Player'}, inplace=True)\n",
    "\n",
    "# Filter to only use salaries from 2019\n",
    "salaries_2019_df = salaries_df[salaries_df['year'] == 2019]\n",
    "\n",
    "# Join the datasets\n",
    "merged_df = pd.merge(salaries_2019_df, batters_df, on='Player', how='inner')\n",
    "\n",
    "# Display the merged dataset\n",
    "print(merged_df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c44e1e-537c-4e32-a498-b90ec1a7177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Pre Processing\n",
    "\n",
    "# Drop columns we won't need\n",
    "merged_df.drop(columns=['playerID'], inplace=True)\n",
    "merged_df.drop(columns=['team'], inplace=True)\n",
    "\n",
    "# Filter out players who have less than 50 at bats\n",
    "filtered_df = merged_df[merged_df['AB'] >= 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a3434e-d49e-4630-a13e-fba150875104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Pete Alonso to predict his salary later using our model\n",
    "chosen_player = filtered_df[filtered_df['Player'] == 'Pete Alonso']\n",
    "\n",
    "# Remove the his row from the DataFrame so it's not used for training or testing\n",
    "filtered_df = filtered_df[filtered_df['Player'] != 'Pete Alonso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83640696-4844-43a9-866c-ef157d514c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year           Player   salary Team Pos  Age    G   AB   R    H  ...  CS  \\\n",
      "0  2019  Eduardo Escobar  6166666  ARI  3B   35  158  636  94  171  ...   1   \n",
      "1  2019        Jake Lamb  4825000  ARI  OF   34   78  187  26   36  ...   0   \n",
      "2  2019       Adam Jones  4500000  ARI  OF   39  137  485  66  126  ...   1   \n",
      "3  2019       Alex Avila  4250000  ARI   C   37   63  164  22   34  ...   0   \n",
      "4  2019     Jarrod Dyson  4000000  ARI  OF   40  130  400  65   92  ...   4   \n",
      "\n",
      "   BB   SO  SH  SF  HBP    AVG    OBP    SLG    OPS  \n",
      "0  50  130   0  10    3  0.269  0.320  0.511  0.831  \n",
      "1  32   55   0   2    5  0.193  0.323  0.353  0.676  \n",
      "2  31  101   0   3    8  0.260  0.313  0.414  0.727  \n",
      "3  36   68   0   0    1  0.207  0.353  0.421  0.774  \n",
      "4  47   86   1   2    2  0.230  0.313  0.320  0.633  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Verifying processing went as expected\n",
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17e8bbdc-f584-41e9-ae4a-6cf4f9e97b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 4508876.223824617\n",
      "R-squared Score: 0.5269883826991046\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Regression(our main model)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Features\n",
    "X = filtered_df[['HR', 'H', 'AVG', 'Age', 'SLG', 'OBP', 'OPS', 'BB']]  \n",
    "# Target\n",
    "y = filtered_df['salary']  \n",
    "\n",
    "\n",
    "# Apply log transformation to salary\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the SVR model\n",
    "svr = SVR(kernel='rbf', C=10, gamma=0.01)\n",
    "svr.fit(X_train_scaled, y_train_log)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_log = svr.predict(X_test_scaled)\n",
    "\n",
    "# Reverse the log transformation for interpretation\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_test = np.expm1(y_test_log)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"R-squared Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4dcb9b4-2cb7-4815-84a8-20622db0e24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature  Importance\n",
      "3     Age    0.725375\n",
      "1       H    0.282499\n",
      "0      HR    0.135981\n",
      "7      BB    0.102782\n",
      "5     OBP    0.044643\n",
      "6     OPS    0.024291\n",
      "2     AVG    0.016007\n",
      "4     SLG    0.012440\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Compute permutation importance\n",
    "perm_importance = permutation_importance(svr, X_test_scaled, y_test_log, n_repeats=10, random_state=42)\n",
    "\n",
    "# Create a DataFrame for feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': ['HR', 'H', 'AVG', 'Age', 'SLG', 'OBP', 'OPS', 'BB'],  # Replace with your feature names\n",
    "    'Importance': perm_importance.importances_mean\n",
    "})\n",
    "\n",
    "# Sort features by importance\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display feature importance\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25fd2a73-6de5-4221-a9ba-2be5f4ea38d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Salary for Pete Alonso: $2,040,880.50\n"
     ]
    }
   ],
   "source": [
    "# Extract Pete Alonso's features for prediction\n",
    "X_player = chosen_player[['HR', 'H', 'AVG', 'Age', 'SLG', 'OBP', 'OPS', 'BB']].copy()  # Make a copy to avoid warnings\n",
    "\n",
    "# For changing his age to see how salary prediction is affected\n",
    "#X_player.loc[:, 'Age'] = 30\n",
    "\n",
    "# Scale the features using the same scaler used for training\n",
    "X_player_scaled = scaler.transform(X_player)\n",
    "\n",
    "# Predict the log-transformed salary using the SVR model\n",
    "player_salary_log = svr.predict(X_player_scaled)\n",
    "\n",
    "# Reverse the log transformation to get the actual salary\n",
    "player_salary = np.expm1(player_salary_log)\n",
    "\n",
    "# Output the predicted salary\n",
    "print(f\"Predicted Salary for Pete Alonso: ${player_salary[0]:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dc3bbb0-ef62-4cb2-a0f2-f6ec45a006a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Tuning the hyperparameters for RBF kernel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for RBF kernel\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],       # Regularization parameter\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1, 1]  # Kernel coefficient\n",
    "}\n",
    "\n",
    "# Perform Grid Search with RBF kernel\n",
    "grid_search = GridSearchCV(SVR(kernel='rbf'), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train_log)\n",
    "\n",
    "# Display the best parameters and model\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "svr = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ad59619-ecfb-43d3-8f1d-de688823746a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 4772336.273188315\n",
      "R-squared Score: 0.4700959288963734\n"
     ]
    }
   ],
   "source": [
    "# Linear regression(control to compare to our other models)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Features and Target\n",
    "X = filtered_df[['HR', 'H', 'AVG', 'Age', 'SLG', 'OBP', 'OPS', 'BB']]  \n",
    "y = filtered_df['salary']  \n",
    "\n",
    "# Apply log transformation to salary\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the Linear Regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train_log)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_log = lr.predict(X_test_scaled)\n",
    "\n",
    "# Reverse the log transformation for interpretation\n",
    "y_pred = np.expm1(y_pred_log) \n",
    "y_test = np.expm1(y_test_log) \n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"R-squared Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ede675bd-b4b3-473f-8bb9-7e1db4076f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 4886104.713525955\n",
      "R-squared Score: 0.4445298564353426\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Features and Target\n",
    "X = filtered_df[['HR', 'H', 'AVG', 'Age', 'SLG', 'OBP', 'OPS', 'BB']]  \n",
    "y = filtered_df['salary']  \n",
    "\n",
    "# Apply log transformation to salary\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the Random Forest model(values from tuning)\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=500,      \n",
    "    max_depth=10,           \n",
    "    min_samples_split=2,   \n",
    "    min_samples_leaf=4,    \n",
    "    random_state=42        \n",
    ")\n",
    "rf.fit(X_train_scaled, y_train_log)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_log = rf.predict(X_test_scaled)\n",
    "\n",
    "# Reverse the log transformation for interpretation\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_test = np.expm1(y_test_log)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"R-squared Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a10352e9-8f84-47f6-a83c-b9a664c4da04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# Tuning hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1)\n",
    "grid_search.fit(X_train_scaled, y_train_log)\n",
    "\n",
    "# Get the best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Use the best model to make predictions\n",
    "y_pred_log = best_rf.predict(X_test_scaled)\n",
    "y_pred = np.expm1(y_pred_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96657600-b5c7-4585-86c5-8f192dc3a02a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
